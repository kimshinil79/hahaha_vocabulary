const { initializeApp } = require('firebase/app');
const {
  getFirestore,
  doc,
  getDoc,
  updateDoc,
  collection,
  getDocs,
} = require('firebase/firestore');
const { pipeline } = require('@xenova/transformers');

// Firebase ì„¤ì •
const firebaseConfig = {
  apiKey: 'AIzaSyAQY-tXbLL-u1MLGDo_keO2HmSnmaAOlF0',
  authDomain: 'memorizewholetext.firebaseapp.com',
  projectId: 'memorizewholetext',
  storageBucket: 'memorizewholetext.appspot.com',
  messagingSenderId: '1017620600279',
  appId: '1:1017620600279:web:1ef89648b5c2d17f56e792',
  measurementId: 'G-HYV1GDPW35',
};

// Firebase ì´ˆê¸°í™”
const app = initializeApp(firebaseConfig);
const db = getFirestore(app);

let transformersExtractorPromise = null;

async function getTransformersExtractor() {
  if (!transformersExtractorPromise) {
    transformersExtractorPromise = pipeline(
      'feature-extraction',
      'Xenova/all-MiniLM-L6-v2'
    );
  }
  return transformersExtractorPromise;
}

// Transformers.jsë¡œ embedding ìƒì„±
async function generateTransformersEmbedding(text) {
  try {
    const extractor = await getTransformersExtractor();
    const output = await extractor(text, { pooling: 'mean', normalize: true });
    
    // Tensorë¥¼ ë°°ì—´ë¡œ ë³€í™˜
    let embedding = [];
    if (Array.isArray(output)) {
      embedding = output;
    } else if (output.data) {
      if (Array.isArray(output.data)) {
        embedding = output.data;
      } else if (output.data && typeof output.data === 'object' && 'length' in output.data) {
        embedding = Array.from(output.data);
      }
    } else if (typeof output === 'object' && 'length' in output) {
      embedding = Array.from(output);
    }
    
    return embedding;
  } catch (error) {
    console.error('Transformers.js Embedding ìƒì„± ì˜¤ë¥˜:', error);
    throw error;
  }
}

// TensorFlow.js ìŠ¤íƒ€ì¼ì˜ embedding ìƒì„± (í•´ì‹± ê¸°ë°˜)
// ì°¸ê³ : ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” Universal Sentence Encoderë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤
function generateTensorFlowEmbedding(text, embeddingSize) {
  try {
    const words = text.toLowerCase().split(/\s+/);
    const tfEmbedding = new Array(embeddingSize).fill(0);
    
    // ë‹¨ì–´ì˜ ìœ„ì¹˜ì™€ ë¬¸ë§¥ì„ ê³ ë ¤í•œ embedding ìƒì„±
    words.forEach((word, wordIdx) => {
      for (let i = 0; i < word.length; i++) {
        const charCode = word.charCodeAt(i);
        // ë‹¨ì–´ì˜ ìœ„ì¹˜ì™€ ë¬¸ë§¥ì„ ê³ ë ¤í•œ ì¸ë±ìŠ¤ ê³„ì‚°
        const pos = (charCode + wordIdx * 100) % embeddingSize;
        // ì‚¬ì¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ë“œëŸ¬ìš´ ë¶„í¬ ìƒì„±
        tfEmbedding[pos] += Math.sin(charCode * 0.01) * (1.0 / (wordIdx + 1));
      }
    });
    
    // ì •ê·œí™” (L2 norm)
    const norm = Math.sqrt(tfEmbedding.reduce((sum, val) => sum + val * val, 0));
    if (norm > 0) {
      return tfEmbedding.map(val => val / norm);
    }
    
    return tfEmbedding;
  } catch (error) {
    console.error('TensorFlow.js Embedding ìƒì„± ì˜¤ë¥˜:', error);
    throw error;
  }
}

// ë‹¨ì–´ì˜ embedding êµ¬ì¡° ì—…ë°ì´íŠ¸
function hasExistingEmbedding(embedding) {
  if (!embedding) return false;
  if (Array.isArray(embedding)) {
    return embedding.length > 0;
  }
  if (typeof embedding === 'object') {
    const transformers = embedding.transformers;
    const tensorflow = embedding.tensorflow;
    if (Array.isArray(transformers) && transformers.length > 0) return true;
    if (Array.isArray(tensorflow) && tensorflow.length > 0) return true;
  }
  return false;
}

function needsStructureUpgrade(embedding) {
  if (!embedding) return false;
  if (Array.isArray(embedding)) return true;
  if (typeof embedding === 'object') {
    if (!('transformers' in embedding) || !('tensorflow' in embedding)) {
      return true;
    }
  }
  return false;
}

async function updateWordEmbeddings(wordKey) {
  try {
    console.log(`ğŸ”¥ Firebaseì—ì„œ "${wordKey}" ë‹¨ì–´ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n`);
    
    // Firebaseì—ì„œ ë‹¨ì–´ ê°€ì ¸ì˜¤ê¸°
    const wordDocRef = doc(db, 'words', wordKey.toLowerCase());
    const wordDocSnap = await getDoc(wordDocRef);
    
    if (!wordDocSnap.exists()) {
      console.error(`âŒ "${wordKey}" ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
      return;
    }
    
    const wordData = wordDocSnap.data();
    console.log(`ğŸ“„ ë‹¨ì–´: ${wordData.word}`);
    console.log(`ğŸ“Š meanings ê°œìˆ˜: ${wordData.meanings?.length || 0}\n`);
    
    if (!wordData.meanings || wordData.meanings.length === 0) {
      console.log('âš ï¸  meaningsê°€ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }
    
    // Transformers.js ëª¨ë¸ ë¡œë“œ
    console.log('ğŸ¤– Transformers.js ëª¨ë¸ ë¡œë”© ì¤‘...');
    console.log('   (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n');
    
    // ê° meaningì— ëŒ€í•´ embedding ìƒì„±
    const updatedMeanings = [];
    let hasChanges = false;
    
    for (let i = 0; i < wordData.meanings.length; i++) {
      const meaning = wordData.meanings[i];
      console.log(`ğŸ“ ì²˜ë¦¬ ì¤‘: ${i + 1}/${wordData.meanings.length} - ${meaning.id || `meaning_${i}`}`);

      const existingEmbedding = meaning.embedding;
      const hasEmbedding = hasExistingEmbedding(existingEmbedding);
      const upgradeStructure = needsStructureUpgrade(existingEmbedding);

      // examplesì˜ ì²« ë²ˆì§¸ ë¬¸ì¥ì„ ì‚¬ìš© (ì˜ì–´ ë¶€ë¶„ë§Œ ì¶”ì¶œ)
      let textToEmbed = '';
      if (meaning.examples && meaning.examples.length > 0) {
        const example = meaning.examples[0];
        const englishPart = example.split('(')[0].trim();
        textToEmbed = englishPart.replace(/\*\*/g, '').trim();
      }

      const canGenerate = Boolean(textToEmbed) && !hasEmbedding;

      if (canGenerate) {
        console.log(`   í…ìŠ¤íŠ¸: "${textToEmbed}"`);
        try {
          console.log(`   ğŸ”„ Transformers.js embedding ìƒì„± ì¤‘...`);
          const transformersEmbedding = await generateTransformersEmbedding(textToEmbed);
          console.log(`   âœ… Transformers.js embedding ì™„ë£Œ (ì°¨ì›: ${transformersEmbedding.length})`);

          console.log(`   ğŸ”„ TensorFlow.js embedding ìƒì„± ì¤‘...`);
          const tensorflowEmbedding = generateTensorFlowEmbedding(textToEmbed, transformersEmbedding.length);
          console.log(`   âœ… TensorFlow.js embedding ì™„ë£Œ (ì°¨ì›: ${tensorflowEmbedding.length})`);

          updatedMeanings.push({
            ...meaning,
            embedding: {
              transformers: transformersEmbedding,
              tensorflow: tensorflowEmbedding,
            },
          });
          hasChanges = true;
          console.log(`   âœ… Embedding êµ¬ì¡° ì—…ë°ì´íŠ¸ ì™„ë£Œ\n`);
          continue;
        } catch (error) {
          console.error(`   âŒ Embedding ìƒì„± ì‹¤íŒ¨:`, error.message);
        }
      }

      if (upgradeStructure) {
        let transformers = [];
        let tensorflow = [];

        if (Array.isArray(existingEmbedding)) {
          transformers = existingEmbedding;
          console.log('   â„¹ï¸ ê¸°ì¡´ ë°°ì—´ êµ¬ì¡°ë¥¼ ìƒˆ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.');
        } else if (existingEmbedding && typeof existingEmbedding === 'object') {
          transformers = Array.isArray(existingEmbedding.transformers)
            ? existingEmbedding.transformers
            : [];
          tensorflow = Array.isArray(existingEmbedding.tensorflow)
            ? existingEmbedding.tensorflow
            : [];
        }

        updatedMeanings.push({
          ...meaning,
          embedding: {
            transformers,
            tensorflow,
          },
        });
        hasChanges = true;
      } else {
        updatedMeanings.push(meaning);
      }

      if (!canGenerate) {
        if (!textToEmbed) {
          console.log('   âš ï¸  ì˜ˆë¬¸ì´ ì—†ì–´ embeddingì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
        } else if (hasEmbedding) {
          console.log('   âœ… ì´ë¯¸ embeddingì´ ì¡´ì¬í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.');
        }
      }

      console.log('');
    }
    
    if (hasChanges) {
      console.log('ğŸ’¾ Firebaseì— ì—…ë°ì´íŠ¸ ì¤‘...');
      await updateDoc(wordDocRef, {
        meanings: updatedMeanings,
        updatedAt: new Date().toISOString(),
      });
      
      console.log('âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n');
      console.log('ğŸ“Š ìš”ì•½:');
      console.log(`   - ì²˜ë¦¬ëœ meanings: ${updatedMeanings.length}ê°œ`);
      const withTransformers = updatedMeanings.filter(
        (m) =>
          m.embedding &&
          m.embedding.transformers &&
          Array.isArray(m.embedding.transformers) &&
          m.embedding.transformers.length > 0
      ).length;
      const withTensorflow = updatedMeanings.filter(
        (m) =>
          m.embedding &&
          m.embedding.tensorflow &&
          Array.isArray(m.embedding.tensorflow) &&
          m.embedding.tensorflow.length > 0
      ).length;
      console.log(`   - Transformers.js embeddingì´ ìˆëŠ” meanings: ${withTransformers}ê°œ`);
      console.log(`   - TensorFlow.js embeddingì´ ìˆëŠ” meanings: ${withTensorflow}ê°œ`);
    } else {
      console.log('â„¹ï¸ ë³€ê²½ ì‚¬í•­ì´ ì—†ì–´ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n');
    }
    
  } catch (error) {
    console.error('ğŸ’¥ ì˜¤ë¥˜ ë°œìƒ:', error);
    process.exit(1);
  }
}

async function processAllWordsSequentially() {
  try {
    console.log('ğŸ“š words ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n');
    const wordsCol = collection(db, 'words');
    const snapshot = await getDocs(wordsCol);

    console.log(`ğŸ”¢ ì´ ${snapshot.size}ê°œì˜ ë‹¨ì–´ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n`);

    let processed = 0;
    for (const docSnap of snapshot.docs) {
      processed += 1;
      const wordKey = docSnap.id;
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
      console.log(`(${processed}/${snapshot.size}) "${wordKey}" ì²˜ë¦¬ ì‹œì‘`);
      await updateWordEmbeddings(wordKey);
    }

    console.log('\nğŸ‰ words ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤!');
  } catch (error) {
    console.error('ğŸ’¥ ì „ì²´ ë‹¨ì–´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    process.exit(1);
  }
}

// ë©”ì¸ ì‹¤í–‰
async function main() {
  const wordKey = process.argv[2];

  console.log('ğŸš€ Embedding êµ¬ì¡° ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘\n');
  console.log('   ìƒˆë¡œìš´ êµ¬ì¡°:');
  console.log('   {');
  console.log('     "embedding": {');
  console.log('       "transformers": [0.12, -0.23, 0.45, ...],');
  console.log('       "tensorflow": [0.09, 0.17, -0.05, ...]');
  console.log('     }');
  console.log('   }\n');

  if (wordKey) {
    console.log(`ğŸ“‹ "${wordKey}" ë‹¨ì–´ì˜ embeddingì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n`);
    await updateWordEmbeddings(wordKey);
    console.log('ğŸ‰ ì™„ë£Œ!');
  } else {
    await processAllWordsSequentially();
  }
}

main();

